---
title: volatile
excerpt: 介绍volatile关键字相关知识
categories:
  - 并发编程
tags:
  - volatile
  - 锁
comments: true
layout: post
index_img: /img/jetbrain/1920x1080-resharper2022_1.png
abbrlink: 4266433718
date: 2022-05-18 20:57:22
---

# 概念

主要是为了解决可见性问题。相对synchronized来说，volatile更加轻量级。可以理解成一个轻量级的锁。它能保证java多线程开发中，共享变量被某个线程修改后，其他线程能读到最新已被修改的值。至于它还解决了有序性问题，是因为它通过内存屏障概念禁止了指令重排序，这些其实说到底都是和硬件语义有关。

所以在具体了解volatile之前，需要对硬件层面的原理做一下说明，这样才能更好理解volatile的工作原理，即明白为啥volatile能实现可见性和有序性，但不能保证原子性。

虽然前述JMM结构和应用场景部分已做了简单介绍，但是还不完整，下面来进行完整说明

# 硬件层面原理

## 硬件内存架构

我们再把之前多级缓存读取那张图重新贴一下

![多级缓存读取](img/volatile/E0AE6141-85FA-4BD2-AA4A-B583DB9CF7BF.png)

在多核多cpu情况下，多核是指在一个cpu中集成了两个或多个完整的计算引擎(内核),这样可以支持多任务并行操作。从多线程调度的角度来说，每个线程会映射到各个cpu核中并行操作。cpu有一组CPU寄存器，它是cpu用来直接访问和处理数据的单元，是一个临时放数据的空间。

一般cpu都会从内存读取数据到寄存器，然后进行操作，但前述已知，内存处理速度远低于cpu，导致cpu处理指令时往往需要很多时间来等待内存做准备工作，于是在寄存器和主内存间添加了cpu缓存，cpu缓存速度快，容量小且昂贵。若cpu总是操作主内存中的同一地址数据，容易影响cpu执行速度，此时cpu缓存就可把从内存中读取的数据暂时保存起来。在cpu寄存器读取内存中同一位置数据时，可直接从缓存中读取，无需直接从主内存读取。

但是需要注意的是，寄存器并不是每次都可以从缓存中读取数据，万一不是同一个内存地址的数据，那寄存器还是必须绕过cpu缓存从内存中读取。所以并不是每次都从缓存中读取数据，这种现象叫做缓存命中，能从缓存中读取就是命中，不能就是没命中。总结下来，就是当一个cpu访问主内存时，会先读取一部分主内存数据到cpu缓存(如果缓存中存在需要的数据，就直接从缓存中读取)，进而再读取cpu缓存数据到寄存器，当cpu需要写数据到主内存时，同样会先刷新寄存器中的数据到cpu缓存，然后再把数据刷新到主内存中。

在前述JMM结构和应用场景部分，已知每个线程都有一个所谓的工作内存。通过前面描述，其实可以明白这个东西其实就是cpu寄存器和高速缓存的一个抽象。简单说可以当做是cpu中的寄存器部分+L1-L3三级cpu高速缓存(仔细看上图，L3是多核cpu共享的，L1-L2是每个cpu核独享的)。而主内存其实就是`RAM(random access memory`,随机存储器),也就是通常所说的电脑内存。今后要是有面试官问你主内存对应计算机硬件什么部分，你大可以大言不惭的说就是内存条。

## Java线程与硬件映射关系

在目前已知各大操作系统中，人们其实是基于一对一的线程模型来实现Java线程。一对一线程模型概念，就是**通过编程语言层面的应用程序去间接调用系统内核的线程模型**。

比如Java，Java虚拟机内部是调用当前操作系统的内核线程来完成当前任务。所谓内核线程(`Kernel-Level Thread`，`KLT`)是由操作系统内核(`Kernel`)支持的线程，它由操作系统内核来完成线程切换，内核通过操作调度器对线程执行调度，并将线程的任务映射到各个cpu上。每个内核线程可视为内核的一个影分身,这也是操作系统可同时处理多任务的原因。

但是在编程语言层面，应用程序一般不会直接去调用内核线程，取而代之是用一种轻量级的进程(`Light Weight Process`)，也就是线程，由于每个轻量级进程都会映射到一个内核线程，因此可通过轻量级进程调用内核线程，进而让操作系统内核把一个个任务映射到一个个cpu上，这种轻量级进程与内核线程1对1的关系也就是一对一的线程模型。

## 原子指令操作

因为是一对一线程模型，所以针对多线程并发操作映射于硬件的关系，下面可以具体说一下读写数据时候，在硬件层面到底发生了什么。

由前述JMM结构，主内存和工作内存之间会同步变量数据。那么，如何让主内存和工作内存互相之间，实现数据同步呢？在JMM中，它定义了8种指令操作来实现。这8种操作每一种都是原子操作

8种原子指令操作如下:
* lock(锁定)
  作用于主内存中的共享变量，它把一个共享变量标识为一个线程独占状态
* unlock(解锁)
  作用于主内存中的共享变量，它把一个处于锁定状态的共享变量释放出来，释放后的共享变量才可被其他线程锁定
* read(读取)
  作用于主内存的共享变量，它把一个共享变量的值从主内存传到线程的工作内存中，方便之后的load动作使用
* load(载入)
  作用于工作内存中的共享变量，它把read操作从主内存中得到的共享变量值放入工作内存中的共享变量副本
* use(使用)
  作用于工作内存中的共享变量，它把工作内存中共享变量值传给执行引擎，虚拟机每次执行一个需要使用到该变量值的字节码指令时，就会执行这个操作
* assign(赋值)
  作用于工作内存中的共享变量，它把从执行引擎接收到的值赋给工作内存的共享变量副本，虚拟机每次执行一个给变量赋值的字节码指令时,就会执行这个操作
* store(存储)
  作用于工作内存的共享变量，它把工作内存中共享变量值传给主内存中，方便之后的write操作使用
* write(操作)
  作用于主内存的共享变量，它把store操作从工作内存中得到的共享变量值放入主内存的共享变量中

其中lock和unlock操作是用于总线锁机制来解决缓存数据不一致问题。总线锁机制就是当一个cpu核执行一个线程去访问数据做操作时，它会向总线发送一个lock信号，此时其他线程去访问主内存数据，就会被阻塞。这样cpu核可独享这个主内存的共享变量。它操作结束后，会发送unlock信号，让其他线程可以对主内存数据进行访问。可以理解成通过把内存和cpu之间的通信锁住，把并行化操作变成串行操作，但这样，其他线程都会被阻塞住，会导致很严重的性能问题，与多核多线程并行操作提升程序性能的目的相悖。

所以后来可以通过其他6种指令操作来实现可见性。

如下图，叙述一下指令操作的整个流程

![指令操作流程](img/volatile/86F235F0-EF8F-4B94-B691-BE7047B13815.png)

假设在多线程并发操作情况下，主内存中共享变量data原来值为0。线程1和线程2都要对data进行自增+1操作，且线程1先进行操作。此时整个流程为
1. 主内存通过read操作，读取到data=0
2. 主内存把值load到线程1的工作内存的共享变量副本data=0
3. 将工作内存中共享变量data值传给执行引擎，线程1的虚拟机需要对data进行自增+1操作，所以会use它
4. 线程1的虚拟机给data变量值赋值为1，将新值data=1传给，即assign给工作内存的共享变量副本
5. store操作将值传回主内存
6. 把data=1通过主内存进行write操作，写入到主内存共享变量中
   7-12线程2对共享变量data操作类似1，不做详述

此外，JMM规定

* 变量从主内存同步到工作内存的过程，需要顺序执行read和load操作
* 变量从工作内存同步到主内存的过程，需要顺序执行store和write操作

但只要求这4个操作必须按顺序执行，并没有规定必须是连续执行

其实JMM对于这些原子指令操作还有另外一些规则，大致罗列一下:

1. 不允许某个线程丢弃它最近的assign操作，即共享变量在工作内存中被改变了之后，必须把该变化同步回主内存
2. 不允许某个线程无原因的（没有发生过任何assign操作）把共享变量值从工作内存同步回主内存
3. 一个新共享变量只能从主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化(load或assign)的共享变量，也就是对一个共享变量实施use和store操作之前，必须先执行过了load和assign操作
4. 一个共享变量在同一时刻只允许一条线程对其执行lock操作，但lock操作可以被同一个条线程重复执行多次，多次执行lock后，一定要执行相同次数的unlock操作，共享变量才会被解锁
5. 如果对一个共享变量执行lock操作，将会清空工作内存中此共享变量的值，在执行引擎use这个共享变量前，需要重新执行load或assign操作初始化共享变量值
6. 如果一个共享变量实现没有被lock操作锁定，则不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定的共享变量
7. 对一个共享变量执行unlock操作之前，必须先把此共享变量同步回主内存(执行store和write操作)

这里有一个问题是线程2操作时，怎么知道data变量值已经为1，而不是重新读0出来再进行自增操作？
这就需要说到下面的缓存一致性协议，这也是除了总线锁机制之外，另外一种实现可见性的手段

## 缓存一致性协议

缓存一致性协议最出名的是`Intel`公司的`MESI`协议，导致现在一说到缓存一致性协议，都马上会说`MESI`协议。其实这是不对的，`MESI`协议只是现在比较标配的一种缓存一致性协议而已(常见的协议还有`MSI`、`MOSI`等)。它的功能是保证每个缓存(工作内存)中使用的共享变量副本内容是一致的。

如今的`cpu`不再是按字节访问内存，而是以64字节为单位的块(`chunk`)读取内存。这就是缓存行。它可被简单理解为`cpu`缓存中的最小缓存单位。而且，共享变量在`cpu`缓存中的存储就是以缓存行为单位，一个缓存行可以存储多个变量，存满当前缓存行字节数64即可。当`cpu`读取一个特定的内存地址时，整个缓存行可将变量从主内存换入缓存。

缓存一致性协议的核心思想:
**当`cpu`写数据时，如果发现操作的变量是共享变量，若在其他`cpu`中也存在该变量的共享变量副本，会发出信号通知其他`cpu`将该变量的置为无效状态，因此当其他`cpu`需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那就会直接从内存中重新读取**

前述线程1，线程2例子中，只要线程1执行store和write操作时，发现变量data是共享变量，且线程2的工作内存中也有data变量的共享变量副本，它就会发出信号通知线程2将data变量置为无效，之后继续执行自己的store和write操作直到结束。在线程2需要对data变量执行read和load操作时，发现自己工作内存中的data变量缓存行是无效的，就直接从主内存即内存中重新读取共享变量data的值，这个时候线程1已执行完store和write操作，data变量在主内存中的值已变为1，那么线程2读取到的data变量值就是1，进行后续use操作就会把data变量值从1自增到2，之后线程2的store和write操作执行时，data变量值就是2了，不会重新再是读取到0后的自增值1了。

但是在细节上，缓存一致性协议还有下面一些内容

它会在cpu缓存中保存一个标记位，以此来标记四种状态。另外，每个缓存不仅知道自己的读写操作，也会监听其它缓存的读写操作，这就是嗅探(snooping)功能。否则它怎么会知道何时发出信号通知其他cpu把缓存行中的变量设为无效呢？

四种状态依次为:

1. M(被修改的,Modify)
   处于这一状态的数据，只在本cpu核中有缓存数据，而其他核中没有。同时其状态相对于内存中的值来说，是已被修改的，只是没有更新到内存中
2. E(独占的,Exclusive)
   处于这一状态的数据，只有在本cpu中有缓存，且其数据没有修改，与内存一致
3. S(共享的,Share)
   处于这一状态的数据在多个cpu中都有缓存，且与内存一致
4. I(无效的,Invalid)
   本cpu中的这份缓存已经无效

cpu的数据读取会遵循下列这些原则（嗅探功能，`snopping`）

1. 处于M状态的缓存行，必须时刻监听所有试图读取该缓存行对应的主内存地址的操作。如果监听到，则必须在此操作执行前把其缓存行中的数据写回cpu
2. 处于S状态的缓存行，必须时刻监听使该缓存行无效或者独享该缓存行的请求。如果监听到，则必须把其缓存行状态设置为I
3. 处于E状态的缓存行，必须时刻监听其他试图读取该缓存行对应的主内存地址的操作。如果监听到，则必须把其缓存行状态设置为S

当cpu需要读数据时，如果其缓存行的状态是I的，则需要从内存中读取，并把自己状态变成S，如果不是I，则可以直接读取缓存中的值，但在此之前，必须要等待其他cpu监听结果，如其他cpu也有该数据的缓存且状态是M，则需要等待其把缓存更新到内存之后，再读取

当cpu需要写数据时，只有在其缓存行是M或者E的时候才能执行，否则需要发出特殊的RFO指令(Read Or Ownership，这是一种总线事务)，通知其他cpu设置缓存无效(I)，这种情况下性能开销是相对较大的。在写入完成后，修改其缓存状态为M

## 缓存一致性协议的不足和改进

不足:
缓存一致性协议也存在一些问题。因为各cpu缓存行状态是通过消息传递来进行。如果某个cpu要对一个共享变量进行写操作，第一步需要发送一个让其他cpu失效缓存行的消息给它们。且要等到它们的确认回执才能继续进行写操作。那么该cpu在这段时间内都会处于阻塞状态

![不足](img/volatile/8A3C65C3-1CD9-4161-BC8C-5BA0FB8A3816.png)

所以为了避免因为阻塞带来的性能浪费。这里就引入了Store Buffer机制

还是以上述cpu例子继续说，它在对共享变量进行写操作时，直接把值写入到store buffer里，然后同时发送缓存行无效消息给其它cpu，接着继续进行其它操作。当收到其他所有cpu发回的确认回执后，再将store buffer里的数据存储至缓存行中。最后再执行store,write操作将缓存行中的共享变量值同步到主内存

但是这还会存在两个问题
1. 共享变量值什么时候提交是不确定的，因为需要等待其他cpu给确认回执后，才会进行数据同步。这其实是一个异步操作
2. 引入了store buffer后，cpu会先尝试从store buffer中读取值，如果store buffer中有数据，则直接从store buffer中读取，否则就会再从缓存行中读取

看似这不是问题啊，但是请看下面例子
``` java
int data=0;
void exeToCPU{
  data=10;
  isFinish=true;
}

void exeToOtherCPUs{
  if(isFinish){
    assert data==10;  
  }
}
```

我们用伪代码表示，exeToCPU和exeToOtherCPUs分别是在某个cpu和其它cpu上执行的操作,data和isFinish都是共享变量(比较low的说明，请多担待)

假如cpu的缓存行中缓存了共享变量isFinish,且状态为E,而data可能是S。此时,cpu执行时，会先把data=10 的指令写入到store buffer中。且通知给其他缓存了data的cpu。在等待其他cpu返回确认回执时，cpu会继续执行isFinish=true这个指令。而因为当前cpu缓存了isFinish且状态为E，所以可直接修改isFinish=true

这时其它某个cpu发起read操作去读取isFinish值可能为true，但是value值不等于10(因为value=10还没写入到主内存啊，即使其它某个cpu已经无效了自己缓存行中的data变量，但是它从主内存读到的data值不一定是10)

在这种情况下，我们可认为是cpu在乱序执行，也可认为也是一种重排序，而这种重排序会带来可见性问题

虽然这种情况不常见，但的确会发生，这样我们之前保证可见性的一切手段其实就不能完全满足了，所以我们接着引入了内存屏障这个概念(也就是说它不光是为了解决有序性问题，也为了完全保证可见性而出现的)来解决上述这两个问题

## 内存屏障

内存屏障(memory barrier):
将store buffer中指令写入到主内存，从而使其他访问同一共享变量的线程保证有可见性

内存屏障指令包括读屏障、写屏障、全屏障
* 读屏障(Load Memory Barrier)
  cpu在读屏障之后的读操作，都在读屏障之后执行。配合写屏障，使得写屏障之前的主内存更新对于读屏障之后的读操作是可见的
* 写屏障(Store Memory Barrier)
  告诉cpu在写屏障之前,所有已存储在store buffer中的数据同步到主内存。简单说，就是使得写屏障之前的指令结果对写屏障之后的读或写是可见的
* 全屏障(Full Memory Barrier)
  确保屏障前的内存读写操作结果提交到主内存之后，再执行屏障后的读写操作

有了它之后，对于前述例子，data=10写入到store buffer之后，有一个写屏障，那么store buffer中的data=10会同步到主内存，其他cpu发起读操作，写屏障之后的读写操作都可见它之前的指令结果，也就是都可见data和isFinish这两个变量和其最新值10和true，那么其他cpu都能读到data变量最新值10，也就避免出现了可见性问题

总结一下，内存屏障作用是通过防止cpu对主内存的乱序访问，来保证共享变量和其值的可见性。

但内存屏障是如何出现的呢？前述的lock指令，其实就相当于实现了一种内存屏障

## 内存屏障的进一步解释

前述JMM章节已说重排序包括编译器和处理器重排序两种。如下图

![重排序](img/volatile/5B7B6DF9-BA01-4BDD-87C4-060580603C5D.png)

2和3属于处理器重排序。这些重排序可能会导致可见性问题，但前述内存屏障已说了一部分如何保证可见性的内容，但还没有更加详细说明。我们分别对即处理器重排序和编译器重排序再做说明

### 处理器重排序

JMM会要求编译器生成指令时，插入内存屏障来禁止处理器重排序(当然并不是所有程序都会出现重排序问题)。由此既实现了可见性，又实现了有序性。我们接着往下说为啥可见性和有序性都实现了。

1. 屏障分类
   JMM中把内存屏障分为四类，下列表格说明

| 屏障类型 | 指令示例 | 说明 |
| :--- | :--- | :--- |
| LoadLoad | Load1;LoadLoad;Load2;| 确保Load1数据装载先于Load2以及所有后续Load指令装载 |
| StoreStore | Store1;StoreStore;Store2; | 确保Store1数据对其它cpu可见(刷新到主内存)先于Store2以及所有后续store指令存储 |
| LoadStore |Load1;LoadStore;Store2;  |确保Load1数据装载先于Store2以及所有后续Store指令刷新到主内存  |
| StoreLoad | Store1;StoreLoad;Load2; | 确保Store1数据对其它cpu可见(刷新到主内存)先于Load2以及所有后续store指令存储|


>StoreLoad使该屏障之前所有主内存访问指令(包括load和store指令)完成之后，才执行该屏障之后的内存访问指令。它的开销是4种屏障中最大的。在大多数cpu实现中，它是个万能屏障，兼具其它三种内存屏障的功能

2. 屏障插入策略
   对于volatile关键字操作，JMM提供的内存屏障插入策略如下:

      * 在每个volatile写操作的前面插入一个StoreStore屏障
      * 在每个volatile写操作的后面插入一个StoreLoad屏障
      * 在每个volatile读操作的后面插入一个LoadLoad屏障
      * 在每个volatile读操作的后面再插入一个LoadStore屏障

    结合上述内存屏障分类和插入策略，见下图是如何来实现可见性和有序性

![可见性和有序性](img/volatile/46D74D9D-04D0-452C-B020-B15CB9A31CE8.png)

>看左边`volatile`写这一部分，因为后面有`StoreLoad`屏障，保证共享变量值已同步到主内存，屏障之后的操作都能读取到主内存中共享变量最新值，实现了可见性。
>右边部分，通过`LoadLoad`和`LoadStore`两个屏障，禁止了所有读和写操作和`volatile`读操作的指令重排序，实现了有序性

### 编译器的重排序

编译器重排序和处理器重排序的原则一样，遵守**数据依赖性原则**，这是实现有序性的一个重点

编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序，如下面代码

``` java
a=1;b=a; 

a=1;a=2;

a=b;b=1;
```
这3种情况在单线程里,如果改变代码的执行顺序，都会导致结果不一致，所以重排序不会对这类指令做优化。这种规则也称为as-if-serial(假装串行)。不管怎么重排序，对单个线程来说执行结果不能变。

下面代码
``` java
int a=2; //1

int b=3; //2

int result=a*b; //3
```
1和3、2和3存在数据依赖，所以在最终执行指令中，3不能重排序到1和2之前，否则程序会报错。由于1和2不存在数据依赖，所以可重排序1和2的顺序

由上两部分可知，内存屏障是如何来禁止编译器和处理器重排序的

# volatile实现可见性

大部分已在硬件层面原理章节记述。这里做个总结:

多核多cpu情况下，若某个线程对声明了volatile关键字的变量(共享变量)进行写操作

1. JVM会向cpu发送一条带有lock前缀的指令，lock指令通过总线锁机制，确保回写主内存的操作是原子性的，让缓存行数据(共享变量值)写回了主内存。但其它线程因此会被阻塞，它们自己工作内存中存储的共享变量值仍然是老值，所以并不能保证可见性
2. 由此还需MESI缓存一致性协议，每个cpu缓存通过嗅探功能检查自己的共享变量副本值是否过期，当发现自己缓存行处于S状态(说明自己的缓存行存储的变量是共享变量)，且对应的主内存地址被修改时(有其它cpu缓存对主内存的共享变量发起写请求)，就会设置当前缓存行为无效，需要对共享变量数据进行读写时就会重新从主内存中加载共享变量值
3. 但这样也没完全保证可见性。还存在cpu等待缓存行无效确认消息时间过长和没有及时读取到主内存中共享变量最新值等问题。由此还需Store Buffer机制和内存屏障。而lock前缀指令就相当于一个内存屏障，这样发生指令重排时，不会把后面的指令重排到内存屏障之前的位置。在内存屏障之前，变量所在的缓存行数据(共享变量值)已写回了主内存

总而言之，如果面试中除了能说出来MESI缓存一致性协议，再能解释清楚嗅探功能是如何让各cpu缓存进行通信，知道需要在什么时机下，无效自己共享变量所在的缓存行;什么时机下，可以放心大胆读取主内存中的共享变量。然后能更进一步说明Store Buffer和内存屏障，那么基本上就说清楚了volatile是如何实现可见性的了。

# volatile实现有序性

前述处理器和编译器重排序章节，说明了volatile关键字如何通过内存屏障来实现禁止重排序，但是也说的并不详细。这里再具体说明一下，会提到后续Happens-Before规则中有关volatile的部分(Happens-Before规则后续会详细说)

## volatile通过内存屏障禁止指令重排序最佳示例

通过前面代码示例，我们知道volatile关键字在通过内存屏障禁止编译器重排序方面是通过as-if-serial(假装串行)原则来实现，这里有个最佳示例就是设计模式中单例模式的双重锁模式，代码如下
``` java
import lombok.AccessLevel;
import lombok.NoArgsConstructor;

@NoArgsConstructor(access = AccessLevel.PRIVATE)
public class Singleton {
  /** volatile关键字保证可见性 同时禁用指令重排（jdk1.5后生效） */
  private static volatile Singleton singleton;

  /**
   * 双重检查锁实现单例模式 推荐这样写，既保证线程安全，又延迟加载
   *
   * @return singleton instance
   */
  public static Singleton getSingleton() {
    if (singleton == null) {
      synchronized (Singleton.class) {
        if (singleton == null) {
          singleton = new Singleton();
        }
      }
    }
    return singleton;
  }
}
```
 为啥要使用volatile关键字修饰singleton？

主要因为`singleton = new Singleton();`这句，这不是一个原子操作，事实上在JVM中这句话做了下面3步

1. 给singleton分配内存
2. 调用Singleton的构造方法来初始化成员变量
3. 将singleton对象指向分配的内存空间(执行完这步singleton就不是null了)

但由于指令重排，上述2和3的顺序是不能保证的，最终的执行顺序可能是123也可能是132
若是后者，则在3结束后，2未执行之前，另一个线程执行`if (singleton == null)`，此时singleton已经不是null，但却没有初始化，所以该线程会直接返回singleton，然后使用，自然就会报错

但是根据前述内存屏障用来禁止编译器指令重排序的**数据依赖性原则**，存在数据依赖关系的两个操作的执行顺序不会变，那么2和3顺序在singleton被volatile关键字修饰之后，他们顺序保证是先2后3，就不会出现132这样顺序

## Happens-Before规则中volatile规则

volatile关键字禁止指令重排序其实有两层意思
1. 当程序执行到volatile变量的读或写操作时，在其前面的操作，若涉及变量的更改肯定已全部经进行完成了，且结果已对后面的操作可见，在其后面的操作肯定都还没有开始进行
2. 在进行指令优化时，不能将对volatile变量进行访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行(内存屏障发挥作用)

这解释下来就是Happens-Before规则中volatile规则

volatile变量规则:
对一个volatile变量的写操作先行于之后对这个变量的读操作，这个"之后"指的是时间上的先后顺序

## 总结

volatile关键字通过内存屏障实现了禁止指令重排序功能。内存屏障保证了特定操作的执行顺序(实现有序性)，也保证了共享变量的可见性(实现可见性)

且因为处理器和编译器都能进行指令重排序，如果在指令之间插入一条内存屏障，会告诉编译器和处理器不管在任何情况下，不管啥指令都不能和这条内存屏障进行指令重排序，也就是说，通过插入内存屏障禁止内存屏障前后的指令进行重排序。它的另外一个作用就是强制刷出各个cpu缓存的数据到主内存，让其他任何cpu上的线程(1对1线程模型)都能读取到这些数据的最新值(可见性)

# volatile为何不保证原子性

我参阅了一些网上资料说volatile在某些情况下可以保证原子性，其实这是有条件限制的。平时之所以说volatile不能保证原子性，主要是针对i++这种复合操作，这种操作即使有volatile关键字修饰也不能保证原子性，可能会引发数据不一致问题

为了讲的更加透彻点，我们用两个例子来说明

## i++情况

用之前所用的`int data=0;data=10`的例子来说明(见缓存一致性协议的不足和改进章节)

如果这里是
``` java
volatile int data=0;
data++；
```
假设线程a和线程b两个线程同时从主内存中读取data值，那此时两个线程保存的data值都是0，此时线程a对data进行了自增计算，然后线程b也对data进行了自增计算。按照前述强刷主内存data值，其他线程data值在其工作内存先失效，再从主内存读取data最新值的原理，线程a中data值变为1，线程b根据可见性读取到data=1后，再自增，结果应该是data=2。但是运行结果居然还是1！

实际上，此时针对data变量，实际是做了下面三步原子操作

1. 线程读取data
2. temp=data+1
3. data=temp

当data=0的时，两个线程同时读入data值，然后线程a执行了temp=data+1操作，注意此时的data值还没有变化，然后线程b也执行了temp=data+1操作，这时两个线程保存的data值都是0，temp值都是1，然后线程a执行data=temp(1)操作，此时data值会立即刷新到主内存并通知其他线程保存的data值失效，此时线程b需要重新读取data值。那么此时线程b保存的data值就是1，同时它保存的temp还是1，然后线程b执行data=temp(1)，所以导致计算结果比预期少了1，它还以为data值是1，执行data++操作，预期结果应该是2，谁知道居然还是1

上述例子就表明了volatile保证不了原子性。但是要想能保证，从上面例子可知只要符合下述两条规则就可以了

1. 运算结果并不依赖于变量的当前值，或者能够确保只有一个线程修改变量值
   线程b犯得“错误”就是它运算结果依赖于变量data当前值1，要么就是只让线程a改变data值，线程b它不插手data值修改
2. 变量不需要与其他的状态变量共同参与不变约束
   data变量不要和temp变量搅合在一起。temp变量被赋值为1，其值在两个线程里都不变，但data要执行自增操作，不需要和temp变量一起接受不变约束。所以这个时候不能让temp值赋给data

>如果不符合上述两条规则，要通过加锁(使用synchronized、java.util.concurrent中的锁或原子类)来保证原子性

## i=1情况

这种情况下，JMM有个很奇怪的规定: 针对64位的数据类型，(就是long和double啦),允许虚拟机将没有被volatile修饰的64位数据读写操作划分为两次32位的操作来进行，即允许虚拟机自行选择是否要保证64位数据类型的load、store、read和write这四个操作的原子性

这也被称为long和double的非原子性协定(Non-Atomic Treatment of double and long Variables)

所以会出现一个现象，即多个线程共享一个未声明为volatile关键字的long或double类型变量，且同时对其进行读取和修改操作，那么某些线程可能会读取到一个既不是原值，也不是其他线程修改值的数值(有时被称为“半个变量”)。

这种现象经过测试，在64位Java虚拟机下不会出现，但是在32位Java虚拟机下有时会出现，特别是long类型的变量出现概率最高。所以从java9开始，Java虚拟机增加了一个实验性的参数`-XX: +AlwaysAtomicAccesses`(这是JEP 188对JMM更新的一部分内容)来约束虚拟机对所有数据类型进行原子性访问。而double类型，如今cpu一般都包含专门用于处理浮点数据的浮点运算器(Floating Point Unit，FPU)，用来专门处理单、双精度的浮点数据，所以针对double类型，这种现象哪怕在32位虚拟机下也几乎不会出现

但是如果平时开发用的版本还是java8时候，可以用volatile来修饰long和double类型变量来杜绝上述现象。此时，volatile起的作用就是保证原子性。原因在于: volatile本身不保证获取和设置操作的原子性，仅保持修改的可见性。但是JMM保证声明为volatile的long和double类型变量的get、set操作是原子性的(见[Java语言规范文档(jls-17)](https://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html#jls-17.7)中"`Writes and reads of volatile long and double values are always atomic`"这句)

从上可知，在实际开发中，需要volatile关键字来保证原子性的情况并不多见。
至少我总结下来，要同时满足下列几个条件:
1. Java虚拟机是32位
2. java版本是低于java9的
3. 变量类型为long或double类型，且大概率是long类型变量时候

因此我同意《[深入理解Java虚拟机：JVM高级特性与最佳实践（第3版）](https://weread.qq.com/web/bookDetail/cf1320d071a1a78ecf19254)》一书作者在书中12.3.4小节所说那段话

>笔者的看法是，在实际开发中，除非该数据有明确可知的线程竞争，否则我们在编写代码时一般不需要因为这个原因刻意把用到的long和double变量专门声明为volatile

# 参考资料

1. [本文所有示例源码地址](https://gitee.com/darkranger/beating-interviewer/tree/master/src/main/java/com/wujunshen/thread/jmm)

2. [Java语言规范文档(jls-17)](https://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html#jls-17.7)
